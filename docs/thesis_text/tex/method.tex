\chapter{Human 3D pose from depth images}
%% WHAT IS IMPLEMETED
%% WHY DOES IT REPRESENT A PROGRESS IN RESEARCH
We implemented an algorithm for extraction of human pose in 3D.
Applying methods used on 3-channel (RGB) images to depth images, we show that the same methods can be used to extract objects in 2d images, can be used to extract objects in depth images as well, when it comes to human pose.



\section{Training data preparation}


Skeleton models


\section{2D detection transfer}

(First ideas.)

Torso placement and tree structure for placing.

Fit to human standard model (rules for symmetry and lengths)

Occlusion problem, and interpolated points, visual hull constraints

We train the network on both depth images and a kinematic model of each 3D ground truth location.

\section{Pose from CNN over depth maps}

We create a separate 'side-view' detection map for each 'frontal' detection map. This reduces the convolution operations, since we don't have to convolve over the whole 3D space.
